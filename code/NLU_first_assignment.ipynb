{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU first assignment.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNvEja1IHN183UcwYniOJLF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steveazzolin/NLU-first-assignment/blob/main/code/NLU_first_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7uNQVmKfrRY"
      },
      "source": [
        "# NLU assignment 01\n",
        "## Steve Azzolin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS_6i-YViG-2"
      },
      "source": [
        "#### preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgJLqR_dfVDe"
      },
      "source": [
        "!git clone https://github.com/steveazzolin/nltk.git\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "!pip uninstall nltk\n",
        "!pip install spacy==2.2.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s2keEAVkgcY"
      },
      "source": [
        "!mkdir ../data"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGFuaOr9krJQ"
      },
      "source": [
        "!cp glove.6B.50d.txt ../data"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-gbYRZ0iI73"
      },
      "source": [
        "#### import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRVxDfeuh1H_",
        "outputId": "4617a45a-9e22-4324-d3c7-abaa5cb1cd60"
      },
      "source": [
        "import spacy\n",
        "assert spacy.__version__\n",
        "from spacy import displacy\n",
        "\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "spacy_nlp = spacy.load('en_core_web_sm')\n",
        "sys.path.insert(1, 'nltk/') #to import the local modified version of NLTK\n",
        "\n",
        "import nltk\n",
        "from nltk.parse.transitionparser import TransitionParser, DependencyEvaluator\n",
        "from nltk.corpus import dependency_treebank\n",
        "nltk.download('dependency_treebank');"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package dependency_treebank to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package dependency_treebank is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1xLx7jmicrv"
      },
      "source": [
        "#### supporting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvGXmGRQie3W"
      },
      "source": [
        "def plotDepGraph(spacy_doc):\n",
        "  \"\"\"\n",
        "  function to plot the dependency graph inline\n",
        "  \"\"\"\n",
        "  displacy.render(spacy_doc, style=\"dep\", jupyter=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4BvoSCCjNrI"
      },
      "source": [
        "#### ex01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zulvhxvajM6g",
        "outputId": "e9e6cf7e-a09d-4835-af46-f75dc0137ea7"
      },
      "source": [
        "def es1(sentence:str, debug=False):\n",
        "  \"\"\"\n",
        "  extract a path of dependency relations from the ROOT to a token\n",
        "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
        "    - for each token the path will be a list of dependency relations, where first element is ROOT\n",
        "  \"\"\"\n",
        "  spacy_doc = spacy_nlp(sentence)\n",
        "  if debug: #plot the dependecy graph to inspect friendly the result\n",
        "    plotDepGraph(spacy_doc)\n",
        "\n",
        "  ret = []\n",
        "  for sent in spacy_doc.sents:\n",
        "      for token in sent:\n",
        "        ancestors = \" \".join([t.dep_ for t in token.ancestors][::-1])\n",
        "        ret.append([t.dep_ for t in token.ancestors][::-1])\n",
        "        ret[-1].extend([token.dep_])\n",
        "        if debug: print(\"{}\\t{:15s}\\t{}\".format(token.i, token.text, ancestors))\n",
        "  return ret\n",
        "\n",
        "\n",
        "example = \"I saw the man with a telescope.\"\n",
        "es1(example)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ROOT', 'nsubj'],\n",
              " ['ROOT'],\n",
              " ['ROOT', 'dobj', 'det'],\n",
              " ['ROOT', 'dobj'],\n",
              " ['ROOT', 'dobj', 'prep'],\n",
              " ['ROOT', 'dobj', 'prep', 'pobj', 'det'],\n",
              " ['ROOT', 'dobj', 'prep', 'pobj'],\n",
              " ['ROOT', 'punct']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNkIrxszjRkP"
      },
      "source": [
        "#### ex02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6mPB6AHjNAf",
        "outputId": "c3bc83e0-a6af-4e57-9785-c50468551113"
      },
      "source": [
        "def es2(sentence:str, debug=False):\n",
        "  \"\"\"\n",
        "  extract subtree of a dependents given a token\n",
        "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
        "    - for each token in Doc objects you extract a subtree of its dependents as a list (ordered w.r.t. sentence order)\n",
        "  \"\"\"\n",
        "  spacy_doc = spacy_nlp(sentence)\n",
        "  if debug: #plot the dependecy graph to inspect friendly the result\n",
        "    plotDepGraph(spacy_doc)\n",
        "\n",
        "  ret = []\n",
        "  for sent in spacy_doc.sents:\n",
        "      for token in sent:\n",
        "        desc = \" \".join([t.text for t in token.subtree])\n",
        "        ret.append([t.text for t in token.subtree])\n",
        "        if debug: print(\"{}\\t{:15s}\\t{}\".format(token.i, token.text, desc))\n",
        "  return ret\n",
        "\n",
        "\n",
        "example = \"I saw the man with a telescope.\"\n",
        "es2(example)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['I'],\n",
              " ['I', 'saw', 'the', 'man', 'with', 'a', 'telescope', '.'],\n",
              " ['the'],\n",
              " ['the', 'man', 'with', 'a', 'telescope'],\n",
              " ['with', 'a', 'telescope'],\n",
              " ['a'],\n",
              " ['a', 'telescope'],\n",
              " ['.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgTXWExyjVYX"
      },
      "source": [
        "#### ex03"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx1CzWW1jNFf",
        "outputId": "a2f58b2d-ff6f-4a53-d7d4-90e1561fc10d"
      },
      "source": [
        "def es3(sentence:str, subtree:list, debug=False):\n",
        "  \"\"\"\n",
        "  check if a given list of tokens (segment of a sentence) forms a subtree\n",
        "    - you parse a sentence and get a Doc object of spaCy\n",
        "    - providing as an input ordered list of words from a sentence, you output True/False based on the sequence forming a subtree or not\n",
        "  \"\"\"\n",
        "  assert \" \".join(subtree) in sentence\n",
        "  spacy_doc = spacy_nlp(sentence)\n",
        "  if debug: #plot the dependecy graph to inspect friendly the result\n",
        "    plotDepGraph(spacy_doc)\n",
        "\n",
        "  for sent in spacy_doc.sents:\n",
        "      for token in sent:\n",
        "        desc = [t.text for t in token.subtree] #or one might reuse the function defined by es2()\n",
        "        if desc == subtree:\n",
        "          return True\n",
        "  return False\n",
        "\n",
        "\n",
        "example = \"I saw the man with a telescope.\"\n",
        "es3(example, [\"the\", \"man\", \"with\", \"a\", \"telescope\"]) , es3(example, [\"man\", \"with\", \"a\", \"telescope\"])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ_5UUP5jYIY"
      },
      "source": [
        "#### ex04"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhz60BQJjNKn",
        "outputId": "99b661d5-886b-4d9e-e548-d77096c473b1"
      },
      "source": [
        "def es4(words:str, debug=False):\n",
        "  \"\"\"\n",
        "  identify head of a span, given its tokens\n",
        "    - input is a sequence of words (not necessarily a sentence)\n",
        "    - output is the head of the span (single word)\n",
        "  \"\"\"\n",
        "  spacy_doc = spacy_nlp(words)\n",
        "  if debug: #plot the dependecy graph to inspect friendly the result\n",
        "    plotDepGraph(spacy_doc)\n",
        "  return list(spacy_doc.sents)[0].root\n",
        "\n",
        "\n",
        "example = \"I saw the man with a telescope.\"\n",
        "es4(example)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "saw"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_wVWyzmjbY3"
      },
      "source": [
        "#### ex05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJQ2V5MejcYo",
        "outputId": "876f54b7-7678-4091-8d1b-bfa441b6f2cd"
      },
      "source": [
        "def es5(words:str, debug=False):\n",
        "  \"\"\"\n",
        "  extract sentence subject, direct object and indirect object spans\n",
        "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
        "    - output is lists of words that form a span (not a single word) for subject, direct object, and indirect object (if present of course, otherwise empty)\n",
        "      - dict of lists, is better\n",
        "  in particular, I extract tokens with the mentioned dependecy relations, but only the one forming a subtree (TODO ?????)\n",
        "  \"\"\"\n",
        "  spacy_doc = spacy_nlp(words)\n",
        "  if debug: #plot the dependecy graph to inspect friendly the result\n",
        "    plotDepGraph(spacy_doc)\n",
        "\n",
        "  ret = {\"nsubj\":[], \"dobj\":[], \"iobj\":[]}\n",
        "  for sent in spacy_doc.sents:\n",
        "      for token in sent:\n",
        "        if token.dep_ in [\"nsubj\", \"dobj\", \"iobj\"]:\n",
        "          #if [t.text for t in token.subtree] != [token.text]: #if it forms a span\n",
        "          ret[token.dep_].append(\" \".join([t.text for t in token.subtree]))\n",
        "  return ret\n",
        "\n",
        "\n",
        "example = \"I saw the man with a telescope.\"\n",
        "es5(example)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dobj': ['the man with a telescope'], 'iobj': [], 'nsubj': ['I']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXT5Sw-kjfuI"
      },
      "source": [
        "#### extra point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO6KqfB7h74H",
        "outputId": "9f2c40d2-5851-40a8-a214-4c888f9e601b"
      },
      "source": [
        "%%time\n",
        "\n",
        "def extra_point():\n",
        "  tp = TransitionParser('arc-standard', use_glove=False, linear_svm=False)\n",
        "  tp.train(dependency_treebank.parsed_sents()[:100], 'tp.model')\n",
        "  parses = tp.parse(dependency_treebank.parsed_sents()[-20:], 'tp.model')\n",
        "  de = DependencyEvaluator(parses, dependency_treebank.parsed_sents()[-20:])\n",
        "  las, uas = de.eval()\n",
        "  print(\"\\nLAS={} USA={} without GLOVE\\n\".format(round(las,2), round(uas,2)))\n",
        "\n",
        "  tp = TransitionParser('arc-standard', use_glove=True, linear_svm=False)\n",
        "  tp.train(dependency_treebank.parsed_sents()[:100], 'tp.model')\n",
        "  parses = tp.parse(dependency_treebank.parsed_sents()[-20:], 'tp.model')\n",
        "  de = DependencyEvaluator(parses, dependency_treebank.parsed_sents()[-20:])\n",
        "  las, uas = de.eval()\n",
        "  print(\"\\nLAS={} USA={} with GLOVE\\n\".format(round(las,2), round(uas,2)))\n",
        "\n",
        "\n",
        "  results = []\n",
        "  times = []\n",
        "  train_data_to_test = [100, 300]# 100, 300, 500, 1000\n",
        "  pbar = tqdm(total=len(train_data_to_test*2))\n",
        "  for i , linear in enumerate([True, False]): #enable/disable LinearSVC\n",
        "    results.append([])\n",
        "    times.append([])\n",
        "    for train_data in train_data_to_test:    \n",
        "      start = time.time()\n",
        "      tp = TransitionParser('arc-standard', use_glove=False, linear_svm=linear)\n",
        "      tp.train(dependency_treebank.parsed_sents()[:train_data], 'tp.model')\n",
        "\n",
        "      times[i].append(time.time()-start)\n",
        "\n",
        "      parses = tp.parse(dependency_treebank.parsed_sents()[-20:], 'tp.model')\n",
        "      de = DependencyEvaluator(parses, dependency_treebank.parsed_sents()[-20:])\n",
        "      las, _ = de.eval()\n",
        "      results[i].append(las)\n",
        "      pbar.update(1)      \n",
        "  pbar.close()\n",
        "\n",
        "  ax1 = plt.subplot(211)\n",
        "  ax1.plot(train_data_to_test, results[0], label=\"LinearSVC\")\n",
        "  ax1.plot(train_data_to_test, results[1], label=\"SVC\")\n",
        "  ax1.set(xlabel='n° training samples', ylabel='LAS', title='LAS scores')\n",
        "  plt.legend()\n",
        "\n",
        "  ax2 = plt.subplot(212, sharex=ax1)\n",
        "  ax2.plot(train_data_to_test, times[0], label=\"LinearSVC\")\n",
        "  ax2.plot(train_data_to_test, times[1], label=\"SVC\")\n",
        "  ax2.set(xlabel='n° training samples', ylabel='Training time\\n (s)', title='Training times')\n",
        "\n",
        "  plt.legend()\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "extra_point()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Number of training examples : 100\n",
            " Number of valid (projective) examples : 100\n",
            "\n",
            "LAS=0.77 USA=0.77 without GLOVE\n",
            "\n",
            "Reading GLOVE....\n",
            "GLOVE read\n",
            " Number of training examples : 100\n",
            " Number of valid (projective) examples : 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "LAS=0.09 USA=0.09 with GLOVE\n",
            "\n",
            " Number of training examples : 100\n",
            " Number of valid (projective) examples : 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa1vxbqui1-P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}